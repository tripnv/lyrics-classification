{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cudf\n",
    "import numpy as np \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns \n",
    "import xgboost\n",
    "import mlflow\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from cuml.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, matthews_corrcoef, precision_score, recall_score, f1_score, accuracy_score, classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf, cuml, cupy\n",
    "# from cuml.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/01/16 00:59:32 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "2023/01/16 00:59:32 INFO mlflow.tracking.fluent: Autologging successfully enabled for xgboost.\n",
      "2023/01/16 00:59:32 INFO mlflow.tracking.fluent: Autologging successfully enabled for statsmodels.\n"
     ]
    }
   ],
   "source": [
    "mlflow.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_params = {\n",
    "    'font.family': 'Ubuntu',\n",
    "    'font.weight': 'light',\n",
    "    \n",
    "    'figure.figsize': (15,5),\n",
    "    'figure.frameon': False, \n",
    "    'figure.titlesize': 'xx-large',\n",
    "    'figure.titleweight': 'normal',\n",
    "    \n",
    "    'axes.titlesize': 'x-large',\n",
    "    'axes.titlecolor': 'black',\n",
    "    'axes.titleweight': 'normal',\n",
    "    'axes.titlelocation': 'center',\n",
    "    'axes.labelsize': 'x-large',\n",
    "\n",
    "    'grid.alpha': .25, \n",
    "    'legend.frameon':False,\n",
    "    'xtick.labelsize': 'x-large',\n",
    "    'ytick.labelsize': 'x-large',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.rcParams.update(plot_params)\n",
    "sns.set_palette('mako')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1943\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lyrics-Genre-Test-GroundTruth.csv', 'Lyrics-Genre-Train.csv']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = 'data/Lyrics-Genre-Train.csv'\n",
    "TEST_PATH = 'data/Lyrics-Genre-Test-GroundTruth.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(TRAIN_PATH)\n",
    "test_data = pd.read_csv(TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = train_data[['Lyrics']], train_data['Genre']\n",
    "\n",
    "X_test, Y_test = test_data[['Lyrics']], test_data['Genre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song</th>\n",
       "      <th>Song year</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Track_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>forest-enthroned</td>\n",
       "      <td>2007</td>\n",
       "      <td>catamenia</td>\n",
       "      <td>Metal</td>\n",
       "      <td>I am a night in to the darkness, only soul los...</td>\n",
       "      <td>18096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>superhero</td>\n",
       "      <td>2010</td>\n",
       "      <td>aaron-smith</td>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>Yeah\\nSometimes, i just wanna fly away.\\nThey ...</td>\n",
       "      <td>22724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chicago-now</td>\n",
       "      <td>2007</td>\n",
       "      <td>fall</td>\n",
       "      <td>Metal</td>\n",
       "      <td>Do you work hard?\\nDo you work hard?\\nYou don'...</td>\n",
       "      <td>24760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the-secret</td>\n",
       "      <td>2007</td>\n",
       "      <td>geto-boys</td>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>You know what? I'm destined to be the last man...</td>\n",
       "      <td>24176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>be-the-lake</td>\n",
       "      <td>2011</td>\n",
       "      <td>brad-paisley</td>\n",
       "      <td>Country</td>\n",
       "      <td>There ain't nothing that I would rather see\\nT...</td>\n",
       "      <td>17260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18508</th>\n",
       "      <td>i-wish-he-didn-t-trust-me-so-much</td>\n",
       "      <td>2008</td>\n",
       "      <td>bobby-womack</td>\n",
       "      <td>R&amp;B</td>\n",
       "      <td>I'm the best friend he's got\\nI'd give him the...</td>\n",
       "      <td>12033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18509</th>\n",
       "      <td>i-totally-miss-you</td>\n",
       "      <td>2006</td>\n",
       "      <td>bad-boys-blue</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Bad Boys Blue\\n\"I Totally Miss You\"\\nI did you...</td>\n",
       "      <td>15987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18510</th>\n",
       "      <td>sorry-for-love</td>\n",
       "      <td>2002</td>\n",
       "      <td>celine-dion</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Forgive me for the things\\nThat I never said t...</td>\n",
       "      <td>2722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18511</th>\n",
       "      <td>cure-for-aids</td>\n",
       "      <td>2008</td>\n",
       "      <td>dan-bern</td>\n",
       "      <td>Indie</td>\n",
       "      <td>The day they found a cure for AIDS\\nThe day th...</td>\n",
       "      <td>10221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18512</th>\n",
       "      <td>iceberg-meadows</td>\n",
       "      <td>2015</td>\n",
       "      <td>crawdad-republic</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Fourth of July has come, it's custom that we g...</td>\n",
       "      <td>13657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18513 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Song  Song year            Artist  \\\n",
       "0                       forest-enthroned       2007         catamenia   \n",
       "1                              superhero       2010       aaron-smith   \n",
       "2                            chicago-now       2007              fall   \n",
       "3                             the-secret       2007         geto-boys   \n",
       "4                            be-the-lake       2011      brad-paisley   \n",
       "...                                  ...        ...               ...   \n",
       "18508  i-wish-he-didn-t-trust-me-so-much       2008      bobby-womack   \n",
       "18509                 i-totally-miss-you       2006     bad-boys-blue   \n",
       "18510                     sorry-for-love       2002       celine-dion   \n",
       "18511                      cure-for-aids       2008          dan-bern   \n",
       "18512                    iceberg-meadows       2015  crawdad-republic   \n",
       "\n",
       "         Genre                                             Lyrics  Track_id  \n",
       "0        Metal  I am a night in to the darkness, only soul los...     18096  \n",
       "1      Hip-Hop  Yeah\\nSometimes, i just wanna fly away.\\nThey ...     22724  \n",
       "2        Metal  Do you work hard?\\nDo you work hard?\\nYou don'...     24760  \n",
       "3      Hip-Hop  You know what? I'm destined to be the last man...     24176  \n",
       "4      Country  There ain't nothing that I would rather see\\nT...     17260  \n",
       "...        ...                                                ...       ...  \n",
       "18508      R&B  I'm the best friend he's got\\nI'd give him the...     12033  \n",
       "18509      Pop  Bad Boys Blue\\n\"I Totally Miss You\"\\nI did you...     15987  \n",
       "18510      Pop  Forgive me for the things\\nThat I never said t...      2722  \n",
       "18511    Indie  The day they found a cure for AIDS\\nThe day th...     10221  \n",
       "18512      Pop  Fourth of July has come, it's custom that we g...     13657  \n",
       "\n",
       "[18513 rows x 6 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am a night in to the darkness, only soul los...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yeah\\nSometimes, i just wanna fly away.\\nThey ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Do you work hard?\\nDo you work hard?\\nYou don'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You know what? I'm destined to be the last man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>There ain't nothing that I would rather see\\nT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18508</th>\n",
       "      <td>I'm the best friend he's got\\nI'd give him the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18509</th>\n",
       "      <td>Bad Boys Blue\\n\"I Totally Miss You\"\\nI did you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18510</th>\n",
       "      <td>Forgive me for the things\\nThat I never said t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18511</th>\n",
       "      <td>The day they found a cure for AIDS\\nThe day th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18512</th>\n",
       "      <td>Fourth of July has come, it's custom that we g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18513 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Lyrics\n",
       "0      I am a night in to the darkness, only soul los...\n",
       "1      Yeah\\nSometimes, i just wanna fly away.\\nThey ...\n",
       "2      Do you work hard?\\nDo you work hard?\\nYou don'...\n",
       "3      You know what? I'm destined to be the last man...\n",
       "4      There ain't nothing that I would rather see\\nT...\n",
       "...                                                  ...\n",
       "18508  I'm the best friend he's got\\nI'd give him the...\n",
       "18509  Bad Boys Blue\\n\"I Totally Miss You\"\\nI did you...\n",
       "18510  Forgive me for the things\\nThat I never said t...\n",
       "18511  The day they found a cure for AIDS\\nThe day th...\n",
       "18512  Fourth of July has come, it's custom that we g...\n",
       "\n",
       "[18513 rows x 1 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(Y_train)\n",
    "Y_train = label_encoder.transform(Y_train)\n",
    "Y_test = label_encoder.transform(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_train = Y_train.astype('category').cat.codes\n",
    "# Y_test = Y_test.astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18513,) (18513,) (7935,) (7935,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = train_test_split(train_data, test_size= .15, random_state = SEED, stratify = train_data['Genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train.loc[:,'Genre'] = label_encoder.transform(train.loc[:,'Genre'])\n",
    "valid.loc[:,'Genre'] = label_encoder.transform(valid.loc[:,'Genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, Y_train, Y_valid = train_test_split(X_train, Y_train, test_size= .15, random_state = SEED, stratify = Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cudf series\n",
    "# X_train_ = cudf.Series(X_train)\n",
    "# X_valid_ = cudf.Series(X_valid)\n",
    "# Y_train_ = cudf.Series(Y_train)\n",
    "# Y_valid_ = cudf.Series(Y_valid)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18513, 6)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song</th>\n",
       "      <th>Song year</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Track_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>forest-enthroned</td>\n",
       "      <td>2007</td>\n",
       "      <td>catamenia</td>\n",
       "      <td>Metal</td>\n",
       "      <td>I am a night in to the darkness, only soul los...</td>\n",
       "      <td>18096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>superhero</td>\n",
       "      <td>2010</td>\n",
       "      <td>aaron-smith</td>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>Yeah\\nSometimes, i just wanna fly away.\\nThey ...</td>\n",
       "      <td>22724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chicago-now</td>\n",
       "      <td>2007</td>\n",
       "      <td>fall</td>\n",
       "      <td>Metal</td>\n",
       "      <td>Do you work hard?\\nDo you work hard?\\nYou don'...</td>\n",
       "      <td>24760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the-secret</td>\n",
       "      <td>2007</td>\n",
       "      <td>geto-boys</td>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>You know what? I'm destined to be the last man...</td>\n",
       "      <td>24176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>be-the-lake</td>\n",
       "      <td>2011</td>\n",
       "      <td>brad-paisley</td>\n",
       "      <td>Country</td>\n",
       "      <td>There ain't nothing that I would rather see\\nT...</td>\n",
       "      <td>17260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Song  Song year        Artist    Genre  \\\n",
       "0  forest-enthroned       2007     catamenia    Metal   \n",
       "1         superhero       2010   aaron-smith  Hip-Hop   \n",
       "2       chicago-now       2007          fall    Metal   \n",
       "3        the-secret       2007     geto-boys  Hip-Hop   \n",
       "4       be-the-lake       2011  brad-paisley  Country   \n",
       "\n",
       "                                              Lyrics  Track_id  \n",
       "0  I am a night in to the darkness, only soul los...     18096  \n",
       "1  Yeah\\nSometimes, i just wanna fly away.\\nThey ...     22724  \n",
       "2  Do you work hard?\\nDo you work hard?\\nYou don'...     24760  \n",
       "3  You know what? I'm destined to be the last man...     24176  \n",
       "4  There ain't nothing that I would rather see\\nT...     17260  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7935, 6)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song</th>\n",
       "      <th>Song year</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Lyrics</th>\n",
       "      <th>Track_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>craftsmanship</td>\n",
       "      <td>2005</td>\n",
       "      <td>buck-65</td>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>Most folks spend their days daydreaming of fin...</td>\n",
       "      <td>8294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>come-on-out</td>\n",
       "      <td>2012</td>\n",
       "      <td>the-elwins</td>\n",
       "      <td>Indie</td>\n",
       "      <td>Take your cold hands and put them on my face\\n...</td>\n",
       "      <td>21621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>riot</td>\n",
       "      <td>2013</td>\n",
       "      <td>bullet-for-my-valentine</td>\n",
       "      <td>Metal</td>\n",
       "      <td>Are you ready it's time for war\\nWe'll break d...</td>\n",
       "      <td>3301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>that-s-what-girls-do</td>\n",
       "      <td>2007</td>\n",
       "      <td>dream-street</td>\n",
       "      <td>Pop</td>\n",
       "      <td>You ask me why I change the color of my hair\\n...</td>\n",
       "      <td>2773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>believe-in-a-dollar</td>\n",
       "      <td>2012</td>\n",
       "      <td>cassidy</td>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>Do you believe in magic in a young girl's hear...</td>\n",
       "      <td>16797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Song  Song year                   Artist    Genre  \\\n",
       "0         craftsmanship       2005                  buck-65  Hip-Hop   \n",
       "1           come-on-out       2012               the-elwins    Indie   \n",
       "2                  riot       2013  bullet-for-my-valentine    Metal   \n",
       "3  that-s-what-girls-do       2007             dream-street      Pop   \n",
       "4   believe-in-a-dollar       2012                  cassidy  Hip-Hop   \n",
       "\n",
       "                                              Lyrics  Track_id  \n",
       "0  Most folks spend their days daydreaming of fin...      8294  \n",
       "1  Take your cold hands and put them on my face\\n...     21621  \n",
       "2  Are you ready it's time for war\\nWe'll break d...      3301  \n",
       "3  You ask me why I change the color of my hair\\n...      2773  \n",
       "4  Do you believe in magic in a young girl's hear...     16797  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(train_data['Genre'], edgecolor = 'white', stat = 'percent')\n",
    "plt.box(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['Genre'].nunique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 10 classes. A somewhat unbalanced dataset. Three classes with less than 5% samples. The majority class being Rock w/ approximately 18% of the entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.groupby.generic.SeriesGroupBy object at 0x7f6ea6ca88e0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.groupby('Genre')['Lyrics']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some samples from each group, should be checked."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file:///home/mikhailtal/Desktop/hnnaharendt/lyrics-project/mlruns'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tracking\n",
    "mlflow.get_tracking_uri()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/01/15 18:07:15 INFO mlflow.tracking.fluent: Autologging successfully enabled for statsmodels.\n",
      "2023/01/15 18:07:15 INFO mlflow.tracking.fluent: Autologging successfully enabled for xgboost.\n",
      "2023/01/15 18:07:15 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n"
     ]
    }
   ],
   "source": [
    "mlflow.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlflow.set_experiment(\n",
    "#     experiment_name = 'lyrics-cls'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Country',\n",
       " 'Electronic',\n",
       " 'Folk',\n",
       " 'Hip-Hop',\n",
       " 'Indie',\n",
       " 'Jazz',\n",
       " 'Metal',\n",
       " 'Pop',\n",
       " 'R&B',\n",
       " 'Rock']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.classes_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metrics\n",
    "def calculate_metrics(Y_true, Y_pred, log = True, verbose = True):\n",
    "    \"\"\" Logging custom metrics of interest to the mlflow server\"\"\"\n",
    "    \n",
    "    # Metrics\n",
    "    acc = accuracy_score(Y_true, Y_pred)\n",
    "    f1 = f1_score(Y_true, Y_pred, average = 'weighted')\n",
    "    precision = precision_score(Y_true, Y_pred, average= 'weighted')\n",
    "    recall = recall_score(Y_true, Y_pred, average = 'weighted')\n",
    "    mcc = matthews_corrcoef(Y_true, Y_pred)\n",
    "    cls_report = classification_report(Y_true, Y_pred, target_names=label_encoder.classes_.tolist())\n",
    "    \n",
    "    # Logging \n",
    "    mlflow.log_metric(key = 'accuracy', value = acc )\n",
    "    mlflow.log_metric(key = 'f1_score', value = f1  )\n",
    "    mlflow.log_metric(key = 'precision', value = precision)\n",
    "    mlflow.log_metric(key = 'recall', value = recall)\n",
    "    mlflow.log_metric(key = 'matthews', value = mcc)\n",
    "    \n",
    "    # Display results in notebook\n",
    "    if verbose:\n",
    "        print('Metrics:')\n",
    "        print(f'\\t Accuracy \\t\\t{acc}')\n",
    "        print(f'\\t F-Score \\t\\t{f1 }')\n",
    "        print(f'\\t Precision \\t\\t{precision}')\n",
    "        print(f'\\t Recall \\t\\t{recall}')\n",
    "        print(f\"\\t Matthew's cc \\t\\t{mcc}\")\n",
    "        print(f'\\n{cls_report}')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///home/mikhailtal/Desktop/hnnaharendt/lyrics-project/mlruns/741618519818827325', creation_time=1673731441480, experiment_id='741618519818827325', last_update_time=1673731441480, lifecycle_stage='active', name='lyrics-classification', tags={}>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(experiment_name='lyrics-classification')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoConfig, AutoTokenizer, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'microsoft/debase_modela-large'\n",
    "DOWNLOADED_MODEL_PATH = './model/microsoft/debase_modela-large'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    pretrained_model_name_or_path= MODEL_NAME,\n",
    "    add_prefix_space = True\n",
    ")\n",
    "model_config = AutoConfig.from_pretrained(MODEL_NAME, add_prefix_space = True)\n",
    "model_base = AutoModel.from_pretrained(MODEL_NAME, config = model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LyricsDataset(Dataset):\n",
    "    def __init__(\n",
    "        self, input_data, tokenizer, max_len, return_pt=True) -> None:\n",
    "        self.input_data = input_data\n",
    "        self.max_len = max_len\n",
    "        self.tokenizer = tokenizer\n",
    "        self.return_pt = return_pt\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.input_data.iloc[idx]\n",
    "        lyrics_text = row['Lyrics']\n",
    "        label = row['Genre']\n",
    "        \n",
    "        if self.return_pt:\n",
    "            label = torch.tensor(label)\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "           text = lyrics_text,\n",
    "           add_special_tokens = True,\n",
    "           padding = 'max_length',\n",
    "           truncation = True,\n",
    "           max_length = self.max_len,\n",
    "        \n",
    "        \n",
    "           return_attention_mask = True,\n",
    "           return_token_type_ids = False,\n",
    "\n",
    "           return_tensors = 'pt' if self.return_pt else 'np'\n",
    "        )\n",
    "\n",
    "        return dict(\n",
    "            lyrics_text = lyrics_text,\n",
    "            input_ids = encoding['input_ids'].flatten(),\n",
    "            attention_mask = encoding['attention_mask'].flatten(),\n",
    "            label = label\n",
    "        )\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LyricsDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, train, valid, test, tokenizer, batch_size = 16, max_token_length = 256) -> None:\n",
    "        super().__init__()\n",
    "    \n",
    "        self.train_data = train\n",
    "        self.valid_data = valid\n",
    "        \n",
    "        if test:\n",
    "            self.test_data = test\n",
    "        else:\n",
    "            self.test_data = None\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "        self.batch_size = batch_size\n",
    "        self.max_token_length = max_token_length\n",
    "\n",
    "    def setup(self, stage = None) -> None:\n",
    "        self.train_dataset = LyricsDataset(self.train_data, tokenizer = tokenizer, max_len=256)\n",
    "\n",
    "        self.valid_dataset = LyricsDataset(self.valid_data, tokenizer = tokenizer, max_len=256)\n",
    "\n",
    "        if self.test_data:\n",
    "            self.test_dataset = LyricsDataset(self.test_data, tokenizer = tokenizer, max_len=256)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size= self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=8\n",
    "        )\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.valid_dataset,\n",
    "            batch_size= self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=8\n",
    "        )\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size= self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=8\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LyricsClassifier(pl.LightningModule):\n",
    "  def __init__(self, model_name, n_classes: int, n_training_steps=None, n_warmup_steps=None):\n",
    "    super().__init__()\n",
    "    model_config = AutoConfig.from_pretrained(model_name, add_prefix_space = True)\n",
    "    self.base_model = AutoModel.from_pretrained(model_name, config = model_config)\n",
    "    \n",
    "    self.classifier = nn.Linear(self.base_model.config.hidden_size, n_classes)\n",
    "    self.n_training_steps = n_training_steps\n",
    "    self.n_warmup_steps = n_warmup_steps\n",
    "    self.criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "  def forward(self, input_ids, attention_mask, label=None):\n",
    "    output = self.base_model(input_ids, attention_mask=attention_mask)\n",
    "    output = self.classifier(output.pooler_output)\n",
    "    \n",
    "    loss = 0\n",
    "    if label is not None:\n",
    "        loss = self.criterion(output, label)\n",
    "    return loss, output\n",
    "\n",
    "  def training_step(self, batch, batch_idx):\n",
    "    input_ids = batch[\"input_ids\"]\n",
    "    attention_mask = batch[\"attention_mask\"]\n",
    "    label = batch[\"label\"]\n",
    "    loss, outputs = self(input_ids, attention_mask, label)\n",
    "    self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
    "    return {\"loss\": loss, \"predictions\": outputs, \"label\": label}\n",
    "\n",
    "  def validation_step(self, batch, batch_idx):\n",
    "    input_ids = batch[\"input_ids\"]\n",
    "    attention_mask = batch[\"attention_mask\"]\n",
    "    label = batch[\"label\"]\n",
    "    loss, outputs = self(input_ids, attention_mask, label)\n",
    "    self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n",
    "    return loss\n",
    "\n",
    "  def test_step(self, batch, batch_idx):\n",
    "    input_ids = batch[\"input_ids\"]\n",
    "    attention_mask = batch[\"attention_mask\"]\n",
    "    label = batch[\"label\"]\n",
    "    loss, outputs = self(input_ids, attention_mask, label)\n",
    "    self.log(\"test_loss\", loss, prog_bar=True, logger=True)\n",
    "    return loss\n",
    "\n",
    "  \n",
    "  def configure_optimizers(self):\n",
    "    optimizer = torch.optim.AdamW(self.parameters(), lr=2e-5)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "      optimizer,\n",
    "      num_warmup_steps=self.n_warmup_steps,\n",
    "      num_training_steps=self.n_training_steps\n",
    "    )\n",
    "    return dict(\n",
    "      optimizer=optimizer,\n",
    "      lr_scheduler=dict(\n",
    "        scheduler=scheduler,\n",
    "        interval='step'\n",
    "      )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mod = LyricsDataModule(train, valid, None, tokenizer)\n",
    "data_mod.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"distilbase_model-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch=len(train) // 16\n",
    "total_training_steps = steps_per_epoch * 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3932, 19660)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warmup_steps = total_training_steps // 5\n",
    "warmup_steps, total_training_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DebertaModel(\n",
       "  (embeddings): DebertaEmbeddings(\n",
       "    (word_embeddings): Embedding(50265, 1024, padding_idx=0)\n",
       "    (LayerNorm): DebertaLayerNorm()\n",
       "    (dropout): StableDropout()\n",
       "  )\n",
       "  (encoder): DebertaEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): DebertaLayer(\n",
       "        (attention): DebertaAttention(\n",
       "          (self): DisentangledSelfAttention(\n",
       "            (in_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "            (pos_dropout): StableDropout()\n",
       "            (pos_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (pos_q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "          (output): DebertaSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): DebertaLayerNorm()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): DebertaIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): DebertaOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): DebertaLayerNorm()\n",
       "          (dropout): StableDropout()\n",
       "        )\n",
       "      )\n",
       "      (1): DebertaLayer(\n",
       "        (attention): DebertaAttention(\n",
       "          (self): DisentangledSelfAttention(\n",
       "            (in_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "            (pos_dropout): StableDropout()\n",
       "            (pos_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (pos_q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "          (output): DebertaSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): DebertaLayerNorm()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): DebertaIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): DebertaOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): DebertaLayerNorm()\n",
       "          (dropout): StableDropout()\n",
       "        )\n",
       "      )\n",
       "      (2): DebertaLayer(\n",
       "        (attention): DebertaAttention(\n",
       "          (self): DisentangledSelfAttention(\n",
       "            (in_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "            (pos_dropout): StableDropout()\n",
       "            (pos_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (pos_q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "          (output): DebertaSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): DebertaLayerNorm()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): DebertaIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): DebertaOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): DebertaLayerNorm()\n",
       "          (dropout): StableDropout()\n",
       "        )\n",
       "      )\n",
       "      (3): DebertaLayer(\n",
       "        (attention): DebertaAttention(\n",
       "          (self): DisentangledSelfAttention(\n",
       "            (in_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "            (pos_dropout): StableDropout()\n",
       "            (pos_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (pos_q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "          (output): DebertaSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): DebertaLayerNorm()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): DebertaIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): DebertaOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): DebertaLayerNorm()\n",
       "          (dropout): StableDropout()\n",
       "        )\n",
       "      )\n",
       "      (4): DebertaLayer(\n",
       "        (attention): DebertaAttention(\n",
       "          (self): DisentangledSelfAttention(\n",
       "            (in_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "            (pos_dropout): StableDropout()\n",
       "            (pos_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (pos_q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "          (output): DebertaSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): DebertaLayerNorm()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): DebertaIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): DebertaOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): DebertaLayerNorm()\n",
       "          (dropout): StableDropout()\n",
       "        )\n",
       "      )\n",
       "      (5): DebertaLayer(\n",
       "        (attention): DebertaAttention(\n",
       "          (self): DisentangledSelfAttention(\n",
       "            (in_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "            (pos_dropout): StableDropout()\n",
       "            (pos_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (pos_q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "          (output): DebertaSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): DebertaLayerNorm()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): DebertaIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): DebertaOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): DebertaLayerNorm()\n",
       "          (dropout): StableDropout()\n",
       "        )\n",
       "      )\n",
       "      (6): DebertaLayer(\n",
       "        (attention): DebertaAttention(\n",
       "          (self): DisentangledSelfAttention(\n",
       "            (in_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "            (pos_dropout): StableDropout()\n",
       "            (pos_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (pos_q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "          (output): DebertaSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): DebertaLayerNorm()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): DebertaIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): DebertaOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): DebertaLayerNorm()\n",
       "          (dropout): StableDropout()\n",
       "        )\n",
       "      )\n",
       "      (7): DebertaLayer(\n",
       "        (attention): DebertaAttention(\n",
       "          (self): DisentangledSelfAttention(\n",
       "            (in_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "            (pos_dropout): StableDropout()\n",
       "            (pos_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (pos_q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "          (output): DebertaSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): DebertaLayerNorm()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): DebertaIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): DebertaOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): DebertaLayerNorm()\n",
       "          (dropout): StableDropout()\n",
       "        )\n",
       "      )\n",
       "      (8): DebertaLayer(\n",
       "        (attention): DebertaAttention(\n",
       "          (self): DisentangledSelfAttention(\n",
       "            (in_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "            (pos_dropout): StableDropout()\n",
       "            (pos_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (pos_q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "          (output): DebertaSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): DebertaLayerNorm()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): DebertaIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): DebertaOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): DebertaLayerNorm()\n",
       "          (dropout): StableDropout()\n",
       "        )\n",
       "      )\n",
       "      (9): DebertaLayer(\n",
       "        (attention): DebertaAttention(\n",
       "          (self): DisentangledSelfAttention(\n",
       "            (in_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "            (pos_dropout): StableDropout()\n",
       "            (pos_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (pos_q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "          (output): DebertaSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): DebertaLayerNorm()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): DebertaIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): DebertaOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): DebertaLayerNorm()\n",
       "          (dropout): StableDropout()\n",
       "        )\n",
       "      )\n",
       "      (10): DebertaLayer(\n",
       "        (attention): DebertaAttention(\n",
       "          (self): DisentangledSelfAttention(\n",
       "            (in_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "            (pos_dropout): StableDropout()\n",
       "            (pos_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (pos_q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "          (output): DebertaSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): DebertaLayerNorm()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): DebertaIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): DebertaOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): DebertaLayerNorm()\n",
       "          (dropout): StableDropout()\n",
       "        )\n",
       "      )\n",
       "      (11): DebertaLayer(\n",
       "        (attention): DebertaAttention(\n",
       "          (self): DisentangledSelfAttention(\n",
       "            (in_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "            (pos_dropout): StableDropout()\n",
       "            (pos_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (pos_q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "          (output): DebertaSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): DebertaLayerNorm()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): DebertaIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): DebertaOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): DebertaLayerNorm()\n",
       "          (dropout): StableDropout()\n",
       "        )\n",
       "      )\n",
       "      (12): DebertaLayer(\n",
       "        (attention): DebertaAttention(\n",
       "          (self): DisentangledSelfAttention(\n",
       "            (in_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "            (pos_dropout): StableDropout()\n",
       "            (pos_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (pos_q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "          (output): DebertaSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): DebertaLayerNorm()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): DebertaIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): DebertaOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): DebertaLayerNorm()\n",
       "          (dropout): StableDropout()\n",
       "        )\n",
       "      )\n",
       "      (13): DebertaLayer(\n",
       "        (attention): DebertaAttention(\n",
       "          (self): DisentangledSelfAttention(\n",
       "            (in_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "            (pos_dropout): StableDropout()\n",
       "            (pos_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (pos_q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "          (output): DebertaSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): DebertaLayerNorm()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): DebertaIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): DebertaOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): DebertaLayerNorm()\n",
       "          (dropout): StableDropout()\n",
       "        )\n",
       "      )\n",
       "      (14): DebertaLayer(\n",
       "        (attention): DebertaAttention(\n",
       "          (self): DisentangledSelfAttention(\n",
       "            (in_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "            (pos_dropout): StableDropout()\n",
       "            (pos_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (pos_q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "          (output): DebertaSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): DebertaLayerNorm()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): DebertaIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): DebertaOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): DebertaLayerNorm()\n",
       "          (dropout): StableDropout()\n",
       "        )\n",
       "      )\n",
       "      (15): DebertaLayer(\n",
       "        (attention): DebertaAttention(\n",
       "          (self): DisentangledSelfAttention(\n",
       "            (in_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "            (pos_dropout): StableDropout()\n",
       "            (pos_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (pos_q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "          (output): DebertaSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): DebertaLayerNorm()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): DebertaIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): DebertaOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): DebertaLayerNorm()\n",
       "          (dropout): StableDropout()\n",
       "        )\n",
       "      )\n",
       "      (16): DebertaLayer(\n",
       "        (attention): DebertaAttention(\n",
       "          (self): DisentangledSelfAttention(\n",
       "            (in_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "            (pos_dropout): StableDropout()\n",
       "            (pos_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (pos_q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "          (output): DebertaSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): DebertaLayerNorm()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): DebertaIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): DebertaOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): DebertaLayerNorm()\n",
       "          (dropout): StableDropout()\n",
       "        )\n",
       "      )\n",
       "      (17): DebertaLayer(\n",
       "        (attention): DebertaAttention(\n",
       "          (self): DisentangledSelfAttention(\n",
       "            (in_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "            (pos_dropout): StableDropout()\n",
       "            (pos_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (pos_q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "          (output): DebertaSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): DebertaLayerNorm()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): DebertaIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): DebertaOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): DebertaLayerNorm()\n",
       "          (dropout): StableDropout()\n",
       "        )\n",
       "      )\n",
       "      (18): DebertaLayer(\n",
       "        (attention): DebertaAttention(\n",
       "          (self): DisentangledSelfAttention(\n",
       "            (in_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "            (pos_dropout): StableDropout()\n",
       "            (pos_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (pos_q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "          (output): DebertaSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): DebertaLayerNorm()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): DebertaIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): DebertaOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): DebertaLayerNorm()\n",
       "          (dropout): StableDropout()\n",
       "        )\n",
       "      )\n",
       "      (19): DebertaLayer(\n",
       "        (attention): DebertaAttention(\n",
       "          (self): DisentangledSelfAttention(\n",
       "            (in_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "            (pos_dropout): StableDropout()\n",
       "            (pos_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (pos_q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "          (output): DebertaSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): DebertaLayerNorm()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): DebertaIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): DebertaOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): DebertaLayerNorm()\n",
       "          (dropout): StableDropout()\n",
       "        )\n",
       "      )\n",
       "      (20): DebertaLayer(\n",
       "        (attention): DebertaAttention(\n",
       "          (self): DisentangledSelfAttention(\n",
       "            (in_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "            (pos_dropout): StableDropout()\n",
       "            (pos_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (pos_q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "          (output): DebertaSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): DebertaLayerNorm()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): DebertaIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): DebertaOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): DebertaLayerNorm()\n",
       "          (dropout): StableDropout()\n",
       "        )\n",
       "      )\n",
       "      (21): DebertaLayer(\n",
       "        (attention): DebertaAttention(\n",
       "          (self): DisentangledSelfAttention(\n",
       "            (in_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "            (pos_dropout): StableDropout()\n",
       "            (pos_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (pos_q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "          (output): DebertaSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): DebertaLayerNorm()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): DebertaIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): DebertaOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): DebertaLayerNorm()\n",
       "          (dropout): StableDropout()\n",
       "        )\n",
       "      )\n",
       "      (22): DebertaLayer(\n",
       "        (attention): DebertaAttention(\n",
       "          (self): DisentangledSelfAttention(\n",
       "            (in_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "            (pos_dropout): StableDropout()\n",
       "            (pos_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (pos_q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "          (output): DebertaSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): DebertaLayerNorm()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): DebertaIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): DebertaOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): DebertaLayerNorm()\n",
       "          (dropout): StableDropout()\n",
       "        )\n",
       "      )\n",
       "      (23): DebertaLayer(\n",
       "        (attention): DebertaAttention(\n",
       "          (self): DisentangledSelfAttention(\n",
       "            (in_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
       "            (pos_dropout): StableDropout()\n",
       "            (pos_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "            (pos_q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "          (output): DebertaSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): DebertaLayerNorm()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (intermediate): DebertaIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): DebertaOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): DebertaLayerNorm()\n",
       "          (dropout): StableDropout()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (rel_embeddings): Embedding(1024, 1024)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_.base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_ = LyricsClassifier(model_name=MODEL_NAME, n_classes=10, n_warmup_steps = warmup_steps, n_training_steps = total_training_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "  dirpath=\"checkpoints\",\n",
    "  filename=\"best-checkpoint\",\n",
    "  save_top_k=1,\n",
    "  verbose=True,\n",
    "  monitor=\"val_loss\",\n",
    "  mode=\"min\"\n",
    ")\n",
    "logger = TensorBoardLogger(\"lightning_logs\", name=\"lyrics_classification\")\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "  logger=logger,\n",
    "  \n",
    "  callbacks=[early_stopping_callback, checkpoint_callback],\n",
    "  max_epochs=10,\n",
    "  gpus=1,\n",
    "  num_sanity_val_steps=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/01/16 02:26:13 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '594f9efdafb04217b746113080b59b20', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "Missing logger folder: lightning_logs/lyrics_classification\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type             | Params\n",
      "------------------------------------------------\n",
      "0 | base_model | DebertaModel     | 405 M \n",
      "1 | classifier | Linear           | 10.2 K\n",
      "2 | criterion  | CrossEntropyLoss | 0     \n",
      "------------------------------------------------\n",
      "405 M     Trainable params\n",
      "0         Non-trainable params\n",
      "405 M     Total params\n",
      "1,620.693 Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "385c34ae565847f7b4ec682d04d08278",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'BaseModelOutput' object has no attribute 'pooler_output'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[183], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(model_, data_mod)\n",
      "File \u001b[0;32m~/mambaforge/envs/rapids@22.12/lib/python3.9/site-packages/mlflow/utils/autologging_utils/safety.py:555\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    553\u001b[0m     patch_function\u001b[39m.\u001b[39mcall(call_original, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    554\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 555\u001b[0m     patch_function(call_original, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    557\u001b[0m session\u001b[39m.\u001b[39mstate \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msucceeded\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    559\u001b[0m try_log_autologging_event(\n\u001b[1;32m    560\u001b[0m     AutologgingEventLogger\u001b[39m.\u001b[39mget_logger()\u001b[39m.\u001b[39mlog_patch_function_success,\n\u001b[1;32m    561\u001b[0m     session,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    565\u001b[0m     kwargs,\n\u001b[1;32m    566\u001b[0m )\n",
      "File \u001b[0;32m~/mambaforge/envs/rapids@22.12/lib/python3.9/site-packages/mlflow/utils/autologging_utils/safety.py:254\u001b[0m, in \u001b[0;36mwith_managed_run.<locals>.patch_with_managed_run\u001b[0;34m(original, *args, **kwargs)\u001b[0m\n\u001b[1;32m    251\u001b[0m     managed_run \u001b[39m=\u001b[39m create_managed_run()\n\u001b[1;32m    253\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 254\u001b[0m     result \u001b[39m=\u001b[39m patch_function(original, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    255\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mException\u001b[39;00m, \u001b[39mKeyboardInterrupt\u001b[39;00m):\n\u001b[1;32m    256\u001b[0m     \u001b[39m# In addition to standard Python exceptions, handle keyboard interrupts to ensure\u001b[39;00m\n\u001b[1;32m    257\u001b[0m     \u001b[39m# that runs are terminated if a user prematurely interrupts training execution\u001b[39;00m\n\u001b[1;32m    258\u001b[0m     \u001b[39m# (e.g. via sigint / ctrl-c)\u001b[39;00m\n\u001b[1;32m    259\u001b[0m     \u001b[39mif\u001b[39;00m managed_run:\n",
      "File \u001b[0;32m~/mambaforge/envs/rapids@22.12/lib/python3.9/site-packages/mlflow/pytorch/_pytorch_autolog.py:370\u001b[0m, in \u001b[0;36mpatched_fit\u001b[0;34m(original, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m [\n\u001b[1;32m    363\u001b[0m         __MLflowPLCallback(\n\u001b[1;32m    364\u001b[0m             client, metrics_logger, run_id, log_models, log_every_n_epoch, log_every_n_step\n\u001b[1;32m    365\u001b[0m         )\n\u001b[1;32m    366\u001b[0m     ]\n\u001b[1;32m    368\u001b[0m client\u001b[39m.\u001b[39mflush(synchronous\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m--> 370\u001b[0m result \u001b[39m=\u001b[39m original(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    372\u001b[0m \u001b[39mif\u001b[39;00m early_stop_callback \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    373\u001b[0m     _log_early_stop_metrics(early_stop_callback, client, run_id)\n",
      "File \u001b[0;32m~/mambaforge/envs/rapids@22.12/lib/python3.9/site-packages/mlflow/utils/autologging_utils/safety.py:536\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original\u001b[0;34m(*og_args, **og_kwargs)\u001b[0m\n\u001b[1;32m    533\u001b[0m         original_result \u001b[39m=\u001b[39m original(\u001b[39m*\u001b[39m_og_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m_og_kwargs)\n\u001b[1;32m    534\u001b[0m         \u001b[39mreturn\u001b[39;00m original_result\n\u001b[0;32m--> 536\u001b[0m \u001b[39mreturn\u001b[39;00m call_original_fn_with_event_logging(_original_fn, og_args, og_kwargs)\n",
      "File \u001b[0;32m~/mambaforge/envs/rapids@22.12/lib/python3.9/site-packages/mlflow/utils/autologging_utils/safety.py:471\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original_fn_with_event_logging\u001b[0;34m(original_fn, og_args, og_kwargs)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    463\u001b[0m     try_log_autologging_event(\n\u001b[1;32m    464\u001b[0m         AutologgingEventLogger\u001b[39m.\u001b[39mget_logger()\u001b[39m.\u001b[39mlog_original_function_start,\n\u001b[1;32m    465\u001b[0m         session,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    469\u001b[0m         og_kwargs,\n\u001b[1;32m    470\u001b[0m     )\n\u001b[0;32m--> 471\u001b[0m     original_fn_result \u001b[39m=\u001b[39m original_fn(\u001b[39m*\u001b[39;49mog_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mog_kwargs)\n\u001b[1;32m    473\u001b[0m     try_log_autologging_event(\n\u001b[1;32m    474\u001b[0m         AutologgingEventLogger\u001b[39m.\u001b[39mget_logger()\u001b[39m.\u001b[39mlog_original_function_success,\n\u001b[1;32m    475\u001b[0m         session,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    479\u001b[0m         og_kwargs,\n\u001b[1;32m    480\u001b[0m     )\n\u001b[1;32m    481\u001b[0m     \u001b[39mreturn\u001b[39;00m original_fn_result\n",
      "File \u001b[0;32m~/mambaforge/envs/rapids@22.12/lib/python3.9/site-packages/mlflow/utils/autologging_utils/safety.py:533\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original.<locals>._original_fn\u001b[0;34m(*_og_args, **_og_kwargs)\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[39m# Show all non-MLflow warnings as normal (i.e. not as event logs)\u001b[39;00m\n\u001b[1;32m    526\u001b[0m \u001b[39m# during original function execution, even if silent mode is enabled\u001b[39;00m\n\u001b[1;32m    527\u001b[0m \u001b[39m# (`silent=True`), since these warnings originate from the ML framework\u001b[39;00m\n\u001b[1;32m    528\u001b[0m \u001b[39m# or one of its dependencies and are likely relevant to the caller\u001b[39;00m\n\u001b[1;32m    529\u001b[0m \u001b[39mwith\u001b[39;00m set_non_mlflow_warnings_behavior_for_current_thread(\n\u001b[1;32m    530\u001b[0m     disable_warnings\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    531\u001b[0m     reroute_warnings\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    532\u001b[0m ):\n\u001b[0;32m--> 533\u001b[0m     original_result \u001b[39m=\u001b[39m original(\u001b[39m*\u001b[39;49m_og_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m_og_kwargs)\n\u001b[1;32m    534\u001b[0m     \u001b[39mreturn\u001b[39;00m original_result\n",
      "File \u001b[0;32m~/mambaforge/envs/rapids@22.12/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:582\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`Trainer.fit()` requires a `LightningModule`, got: \u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    581\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m_lightning_module \u001b[39m=\u001b[39m model\n\u001b[0;32m--> 582\u001b[0m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    583\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    584\u001b[0m )\n",
      "File \u001b[0;32m~/mambaforge/envs/rapids@22.12/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py:38\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     37\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 38\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     40\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     41\u001b[0m     trainer\u001b[39m.\u001b[39m_call_teardown_hook()\n",
      "File \u001b[0;32m~/mambaforge/envs/rapids@22.12/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:624\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    617\u001b[0m ckpt_path \u001b[39m=\u001b[39m ckpt_path \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresume_from_checkpoint\n\u001b[1;32m    618\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_set_ckpt_path(\n\u001b[1;32m    619\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn,\n\u001b[1;32m    620\u001b[0m     ckpt_path,  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    621\u001b[0m     model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    622\u001b[0m     model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    623\u001b[0m )\n\u001b[0;32m--> 624\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mckpt_path)\n\u001b[1;32m    626\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[1;32m    627\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/rapids@22.12/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1061\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1057\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39mrestore_training_state()\n\u001b[1;32m   1059\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39mresume_end()\n\u001b[0;32m-> 1061\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_stage()\n\u001b[1;32m   1063\u001b[0m log\u001b[39m.\u001b[39mdetail(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: trainer tearing down\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1064\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_teardown()\n",
      "File \u001b[0;32m~/mambaforge/envs/rapids@22.12/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1140\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1138\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredicting:\n\u001b[1;32m   1139\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_predict()\n\u001b[0;32m-> 1140\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_train()\n",
      "File \u001b[0;32m~/mambaforge/envs/rapids@22.12/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1153\u001b[0m, in \u001b[0;36mTrainer._run_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pre_training_routine()\n\u001b[1;32m   1152\u001b[0m \u001b[39mwith\u001b[39;00m isolate_rng():\n\u001b[0;32m-> 1153\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_sanity_check()\n\u001b[1;32m   1155\u001b[0m \u001b[39m# enable train mode\u001b[39;00m\n\u001b[1;32m   1156\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/rapids@22.12/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1225\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1223\u001b[0m \u001b[39m# run eval step\u001b[39;00m\n\u001b[1;32m   1224\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m-> 1225\u001b[0m     val_loop\u001b[39m.\u001b[39;49mrun()\n\u001b[1;32m   1227\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_callback_hooks(\u001b[39m\"\u001b[39m\u001b[39mon_sanity_check_end\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1229\u001b[0m \u001b[39m# reset logger connector\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/rapids@22.12/lib/python3.9/site-packages/pytorch_lightning/loops/loop.py:199\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 199\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    200\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    201\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/rapids@22.12/lib/python3.9/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py:152\u001b[0m, in \u001b[0;36mEvaluationLoop.advance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_dataloaders \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    151\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mdataloader_idx\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m dataloader_idx\n\u001b[0;32m--> 152\u001b[0m dl_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepoch_loop\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_fetcher, dl_max_batches, kwargs)\n\u001b[1;32m    154\u001b[0m \u001b[39m# store batch level output per dataloader\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_outputs\u001b[39m.\u001b[39mappend(dl_outputs)\n",
      "File \u001b[0;32m~/mambaforge/envs/rapids@22.12/lib/python3.9/site-packages/pytorch_lightning/loops/loop.py:199\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 199\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    200\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    201\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/rapids@22.12/lib/python3.9/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py:137\u001b[0m, in \u001b[0;36mEvaluationEpochLoop.advance\u001b[0;34m(self, data_fetcher, dl_max_batches, kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mincrement_started()\n\u001b[1;32m    136\u001b[0m \u001b[39m# lightning module methods\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_evaluation_step(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    138\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_evaluation_step_end(output)\n\u001b[1;32m    140\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mincrement_processed()\n",
      "File \u001b[0;32m~/mambaforge/envs/rapids@22.12/lib/python3.9/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py:234\u001b[0m, in \u001b[0;36mEvaluationEpochLoop._evaluation_step\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"The evaluation step (validation_step or test_step depending on the trainer's state).\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \n\u001b[1;32m    225\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[39m    the outputs of the step\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    233\u001b[0m hook_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtest_step\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mtesting \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mvalidation_step\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 234\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49m_call_strategy_hook(hook_name, \u001b[39m*\u001b[39;49mkwargs\u001b[39m.\u001b[39;49mvalues())\n\u001b[1;32m    236\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/mambaforge/envs/rapids@22.12/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1443\u001b[0m, in \u001b[0;36mTrainer._call_strategy_hook\u001b[0;34m(self, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1440\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m   1442\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[Strategy]\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 1443\u001b[0m     output \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1445\u001b[0m \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m   1446\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/mambaforge/envs/rapids@22.12/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py:390\u001b[0m, in \u001b[0;36mStrategy.validation_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecision_plugin\u001b[39m.\u001b[39mval_step_context():\n\u001b[1;32m    389\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, ValidationStep)\n\u001b[0;32m--> 390\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mvalidation_step(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "Cell \u001b[0;32mIn[175], line 33\u001b[0m, in \u001b[0;36mLyricsClassifier.validation_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     31\u001b[0m attention_mask \u001b[39m=\u001b[39m batch[\u001b[39m\"\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     32\u001b[0m label \u001b[39m=\u001b[39m batch[\u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m---> 33\u001b[0m loss, outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(input_ids, attention_mask, label)\n\u001b[1;32m     34\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog(\u001b[39m\"\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m\"\u001b[39m, loss, prog_bar\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, logger\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     35\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/mambaforge/envs/rapids@22.12/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[175], line 14\u001b[0m, in \u001b[0;36mLyricsClassifier.forward\u001b[0;34m(self, input_ids, attention_mask, label)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, input_ids, attention_mask, label\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     13\u001b[0m   output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbase_model(input_ids, attention_mask\u001b[39m=\u001b[39mattention_mask)\n\u001b[0;32m---> 14\u001b[0m   output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclassifier(output\u001b[39m.\u001b[39;49mpooler_output)\n\u001b[1;32m     16\u001b[0m   loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     17\u001b[0m   \u001b[39mif\u001b[39;00m label \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'BaseModelOutput' object has no attribute 'pooler_output'"
     ]
    }
   ],
   "source": [
    "trainer.fit(model_, data_mod)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_texts():\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cudf.core.series.Series"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.fit(X_train)\n",
    "xtrain = vectorizer.transform(X_train)\n",
    "xvalid = vectorizer.transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15736, 831805) (2777, 831805)\n",
      "<class 'scipy.sparse._csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "print(xtrain.shape, xvalid.shape)\n",
    "print(type(xtrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/01/15 18:17:55 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during sklearn autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID a93c68c16132443796cf7be767f0af6a. Failed operations: [MlflowException(\"Changing param values is not allowed. Param with key=\\'verbose\\' was already logged with value=\\'0\\' for run ID=\\'a93c68c16132443796cf7be767f0af6a\\'. Attempted logging new value \\'False\\'.\")]')]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SVC()\n",
    "model.fit(xtrain, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(xvalid)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CountVectorizer; ngram = (1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics:\n",
      "\t Accuracy \t\t0.39250990277277636\n",
      "\t F-Score \t\t0.35207219171845683\n",
      "\t Precision \t\t0.5579499016688811\n",
      "\t Recall \t\t0.39250990277277636\n",
      "\t Matthew's cc \t\t0.31375231055310915\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Country       0.48      0.30      0.37       284\n",
      "  Electronic       0.82      0.04      0.07       231\n",
      "        Folk       0.70      0.09      0.16       173\n",
      "     Hip-Hop       0.83      0.78      0.80       336\n",
      "       Indie       1.00      0.02      0.03       178\n",
      "        Jazz       0.61      0.13      0.21       231\n",
      "       Metal       0.64      0.66      0.65       283\n",
      "         Pop       0.29      0.35      0.32       389\n",
      "         R&B       0.50      0.03      0.06       178\n",
      "        Rock       0.25      0.71      0.37       494\n",
      "\n",
      "    accuracy                           0.39      2777\n",
      "   macro avg       0.61      0.31      0.31      2777\n",
      "weighted avg       0.56      0.39      0.35      2777\n",
      "\n"
     ]
    }
   ],
   "source": [
    "calculate_metrics(Y_valid, Y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "CountVectorizer; ngram = (1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics:\n",
      "\t Accuracy \t\t0.39683111271155924\n",
      "\t F-Score \t\t0.39683111271155924\n",
      "\t Precision \t\t0.39683111271155924\n",
      "\t Recall \t\t0.39683111271155924\n",
      "\t Matthew's cc \t\t0.312109871634615\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.38      0.42       284\n",
      "           1       0.26      0.12      0.16       231\n",
      "           2       0.49      0.20      0.28       173\n",
      "           3       0.84      0.79      0.81       336\n",
      "           4       0.24      0.06      0.09       178\n",
      "           5       0.41      0.27      0.32       231\n",
      "           6       0.59      0.61      0.60       283\n",
      "           7       0.30      0.35      0.33       389\n",
      "           8       0.32      0.12      0.17       178\n",
      "           9       0.25      0.53      0.34       494\n",
      "\n",
      "    accuracy                           0.40      2777\n",
      "   macro avg       0.42      0.34      0.35      2777\n",
      "weighted avg       0.42      0.40      0.38      2777\n",
      "\n"
     ]
    }
   ],
   "source": [
    "calculate_metrics(Y_valid, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CountVectorizer; ngram = (1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics:\n",
      "\t Accuracy \t\t0.409074540871444\n",
      "\t F-Score \t\t0.409074540871444\n",
      "\t Precision \t\t0.409074540871444\n",
      "\t Recall \t\t0.409074540871444\n",
      "\t Matthew's cc \t\t0.3269972964211144\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.39      0.42       284\n",
      "           1       0.26      0.12      0.17       231\n",
      "           2       0.53      0.23      0.32       173\n",
      "           3       0.83      0.79      0.81       336\n",
      "           4       0.26      0.06      0.09       178\n",
      "           5       0.44      0.28      0.34       231\n",
      "           6       0.59      0.63      0.61       283\n",
      "           7       0.31      0.33      0.32       389\n",
      "           8       0.38      0.14      0.20       178\n",
      "           9       0.27      0.58      0.37       494\n",
      "\n",
      "    accuracy                           0.41      2777\n",
      "   macro avg       0.43      0.35      0.36      2777\n",
      "weighted avg       0.43      0.41      0.39      2777\n",
      "\n"
     ]
    }
   ],
   "source": [
    "calculate_metrics(Y_valid, Y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TFidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics:\n",
      "\t Accuracy \t\t0.21389989196975154\n",
      "\t F-Score \t\t0.21389989196975154\n",
      "\t Precision \t\t0.21389989196975154\n",
      "\t Recall \t\t0.21389989196975154\n",
      "\t Matthew's cc \t\t0.10649674176783724\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.10      0.14       284\n",
      "           1       0.10      0.32      0.16       231\n",
      "           2       0.60      0.03      0.07       173\n",
      "           3       0.92      0.39      0.55       336\n",
      "           4       0.09      0.17      0.12       178\n",
      "           5       0.55      0.03      0.05       231\n",
      "           6       0.61      0.04      0.07       283\n",
      "           7       0.22      0.30      0.25       389\n",
      "           8       1.00      0.04      0.08       178\n",
      "           9       0.20      0.37      0.26       494\n",
      "\n",
      "    accuracy                           0.21      2777\n",
      "   macro avg       0.45      0.18      0.17      2777\n",
      "weighted avg       0.43      0.21      0.20      2777\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "calculate_metrics(Y_valid, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics:\n",
      "\t Accuracy \t\t0.17788980914656105\n",
      "\t F-Score \t\t0.17788980914656105\n",
      "\t Precision \t\t0.17788980914656105\n",
      "\t Recall \t\t0.17788980914656105\n",
      "\t Matthew's cc \t\t0.0\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       284\n",
      "           1       0.00      0.00      0.00       231\n",
      "           2       0.00      0.00      0.00       173\n",
      "           3       0.00      0.00      0.00       336\n",
      "           4       0.00      0.00      0.00       178\n",
      "           5       0.00      0.00      0.00       231\n",
      "           6       0.00      0.00      0.00       283\n",
      "           7       0.00      0.00      0.00       389\n",
      "           8       0.00      0.00      0.00       178\n",
      "           9       0.18      1.00      0.30       494\n",
      "\n",
      "    accuracy                           0.18      2777\n",
      "   macro avg       0.02      0.10      0.03      2777\n",
      "weighted avg       0.03      0.18      0.05      2777\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mikhailtal/mambaforge/envs/rapids@22.12/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mikhailtal/mambaforge/envs/rapids@22.12/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/mikhailtal/mambaforge/envs/rapids@22.12/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "calculate_metrics(Y_valid, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids@22.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cdcfd61292b88655bc281c0b128b469f1c14805e62107403790eea070c7840dc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
